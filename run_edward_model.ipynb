{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ed.set_seed(12227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(687276, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stim</th>\n",
       "      <th>unit</th>\n",
       "      <th>isfirst</th>\n",
       "      <th>isrewarded</th>\n",
       "      <th>count</th>\n",
       "      <th>trial</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>57277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stim  unit  isfirst  isrewarded  count  trial  time\n",
       "0     0  1068        0           0      4  57277     0\n",
       "1     0  1069        0           0      1  57277     0\n",
       "2     0  1070        0           0      6  57277     0\n",
       "3     0  1071        0           0      0  57277     0\n",
       "4     0  1072        1           0      3  60250     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv('data/prepared_data.csv')\n",
    "print(dat.shape)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns are:\n",
    "- stim: original stimulus number\n",
    "- unit: recorded neuron number\n",
    "- isfirst, isrewarded: potential regressors of interest\n",
    "- count: spike count during stimulus display period\n",
    "- trial: original trial number\n",
    "- time: unique stimulus code in trimmed dataset (very rare stims removed)\n",
    "\n",
    "We need to do a couple of things to prep the data:\n",
    "- turn unit codes into a 1-based unit index\n",
    "- turn time into a 1-based stim index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687276, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset data for testing\n",
    "#dat = dat.query(\"unit < 1050 & time < 300\")\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 525 526\n",
      "0 797 798\n"
     ]
    }
   ],
   "source": [
    "_, unit = np.unique(dat.unit, return_inverse=True)\n",
    "_, stim = np.unique(dat.time, return_inverse=True)\n",
    "\n",
    "print(np.min(unit), np.max(unit), len(np.unique(unit)))\n",
    "\n",
    "print(np.min(stim), np.max(stim), len(np.unique(stim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687276, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = dat['count'].values\n",
    "Xdat = dat[['isfirst', 'isrewarded']].values\n",
    "Xdat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define some needed constants\n",
    "N = dat.shape[0]  # number of trials\n",
    "NB = 10  # number of trials in minibatch\n",
    "NU = len(np.unique(unit))  # number of units\n",
    "NS = len(np.unique(stim))  # number of stims\n",
    "P = Xdat.shape[1]  # number of specified regressors\n",
    "K = 5  # number of latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative (p) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"pmodel\"):\n",
    "    A = ed.models.Normal(mu=tf.zeros(NU), sigma=tf.ones(NU), name='A')\n",
    "    B = ed.models.Normal(mu=tf.zeros((NU, P)), sigma=tf.ones((NU, P)), name='B')\n",
    "    C = ed.models.Normal(mu=tf.zeros((NU, K)), sigma=tf.ones((NU, K)), name='C')\n",
    "\n",
    "    X = tf.constant(Xdat.astype('float32'))\n",
    "    U = tf.constant(unit)\n",
    "    S = tf.constant(stim)\n",
    "\n",
    "    delta = ed.models.Beta(a=3 * tf.ones(K), b=tf.ones(K), name='delta')\n",
    "    tf.scalar_summary('mean_delta', tf.reduce_mean(delta))\n",
    "    log_delta = tf.log(delta)\n",
    "    tf.scalar_summary('min_log_delta', tf.reduce_min(log_delta))\n",
    "    tf.scalar_summary('mean_log_delta', tf.reduce_mean(log_delta))\n",
    "\n",
    "    pi = tf.exp(tf.cumsum(log_delta), name='pi')\n",
    "    tf.scalar_summary('min_pi', tf.reduce_min(pi))\n",
    "\n",
    "    Z = ed.models.Bernoulli(p=tf.tile(tf.expand_dims(pi, 0), [NS, 1]), name='Z')\n",
    "    tf.scalar_summary('mean_Z', tf.reduce_mean(tf.to_float(Z)))\n",
    "\n",
    "    sig = ed.models.Normal(mu=[-0.1], sigma=[0.1], name='sig')\n",
    "\n",
    "    lam = ed.models.Normal(mu=(tf.gather(A, U) + tf.reduce_sum(tf.gather(B, U) * X, 1) + \n",
    "           tf.reduce_sum(tf.gather(C, U) * tf.gather(tf.to_float(Z), S), 1)), \n",
    "                           sigma=tf.exp(sig), name='lam')\n",
    "    tf.scalar_summary('mean_lam', tf.reduce_mean(lam))\n",
    "\n",
    "\n",
    "    cnt = ed.models.Poisson(lam=tf.nn.softplus(lam), value=tf.ones(N), name='cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition (q) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"qmodel\"):\n",
    "    q_A = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((NU,))), \n",
    "                                            sigma=tf.Variable(tf.random_uniform((NU,))),\n",
    "                                            name='A')\n",
    "    q_B = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((NU, P))), \n",
    "                                            sigma=tf.Variable(tf.random_uniform((NU, P))),\n",
    "                                            name='B')\n",
    "    q_C = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((NU, K))), \n",
    "                                            sigma=tf.Variable(tf.random_uniform((NU, K))),\n",
    "                                            name='C')\n",
    "    q_Z = ed.models.BernoulliWithSigmoidP(p=tf.Variable(tf.random_normal((NS, K))), name='Z')\n",
    "    tf.scalar_summary('mean_q_Z', tf.reduce_mean(tf.to_float(Z)))\n",
    "\n",
    "    q_delta = ed.models.BetaWithSoftplusAB(a=tf.Variable(1 + tf.random_uniform((K,))),\n",
    "                                           b=tf.Variable(1 + tf.random_uniform((K,))),\n",
    "                                           name='delta')\n",
    "    tf.scalar_summary('mean_q_delta', tf.reduce_mean(q_delta))\n",
    "\n",
    "    q_lam = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((N,))),\n",
    "                                              sigma=tf.Variable(tf.random_uniform((N,))),\n",
    "                                              name='lam')\n",
    "    tf.scalar_summary('mean_q_lam', tf.reduce_mean(q_lam))\n",
    "\n",
    "    q_sig = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(-0.1 * tf.random_uniform((1,))),\n",
    "                                              sigma=tf.Variable(tf.random_uniform((1,))),\n",
    "                                              name='sig')\n",
    "    tf.scalar_summary('mean_q_sig', tf.reduce_mean(q_sig))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {cnt: count}\n",
    "inference = ed.KLqp({A: q_A, B: q_B, C: q_C, Z: q_Z, sig: q_sig, delta: q_delta, lam: q_lam}, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes before inference:\n",
    "\n",
    "- The `logdir` keyword specifies the place to put the log file (assuming you've instrumented the code to save events, etc.). If a subdirectory is given, pointing Tensorboard at the parent directory allows you to compare across subdirectories (runs).\n",
    "    - I'm using the `jmp/instrumented` branch of the `jmxpearson/edward` fork\n",
    "- I had to lower the learning rate in Adam to avoid NaNs early on in learning. Gradient clipping might solve the same problem.\n",
    "- I'm currently using \"all\" the data, but this should probably be switched to minibatches.\n",
    "- I've used `n_samples` = 1, 5, 10, and 25, which all seem pretty similar after 10k iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    1 [  0%]: Loss = 26108448.000\n",
      "Iteration  100 [ 10%]: Loss = 6635718.500\n",
      "Iteration  200 [ 20%]: Loss = 33685660.000\n",
      "Iteration  300 [ 30%]: Loss = 5678695.000\n",
      "Iteration  400 [ 40%]: Loss = 23927398.000\n",
      "Iteration  500 [ 50%]: Loss = 5479865.000\n",
      "Iteration  600 [ 60%]: Loss = 8164009.000\n",
      "Iteration  700 [ 70%]: Loss = 4888656.500\n",
      "Iteration  800 [ 80%]: Loss = 7993082.500\n",
      "Iteration  900 [ 90%]: Loss = 16878524.000\n",
      "Iteration 1000 [100%]: Loss = 25808708.000\n"
     ]
    }
   ],
   "source": [
    "inference.run(n_iter=1000, n_print=100, n_samples=1, logdir='data/run1',\n",
    "             optimizer=tf.train.AdamOptimizer(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
