{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model on fake data\n",
    "\n",
    "Here, we generate a synthetic data set for purposes of validating the model constructed in Edward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ed.set_seed(12225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is defined by the spike count $N_{us}$ observed when stimulus $s$ is presented to unit $u$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "N &\\sim \\mathrm{Poisson}((\\lambda)_+)  \\\\\n",
    "\\lambda_{us} &\\sim \\mathcal{N}(A_{u} + (B * X)_{us} + (C * Z)_{us}, \\sigma^2) \\\\\n",
    "\\log \\sigma &\\sim \\mathcal{N}(-0.1, 0.1^2) \\\\\n",
    "Z_{ks} &\\sim \\mathrm{Bernoulli}(\\pi_k) \\\\\n",
    "\\pi_k &\\equiv \\prod_{i=1}^k \\delta_k \\\\\n",
    "\\delta_j &\\sim \\mathrm{Beta}(3, 1)\n",
    "\\end{align}\n",
    "$$\n",
    "With $X$ an $P \\times N_s$ matrix of known regressors, $Z$ a $K \\times N_s$ matrix of latent binary features\n",
    "governed by an Indian Buffet Process, $A$ and $N_u$ vector of baselines, and $(\\cdot)_+$ the softplus function: \n",
    "$(x)_+ = \\log(1 + e^x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic constants\n",
    "N = 5  # number of observations per unit per stim\n",
    "NB = 10  # number of trials in minibatch\n",
    "NU = 50  # number of units\n",
    "NS = 50  # number of stims\n",
    "P = 5  # number of specified regressors\n",
    "K = 5  # number of latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make neural response coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dA = 5 + 2 * np.random.randn(NU)  # baseline\n",
    "dB = 5 + 3 * np.random.randn(NU, P)  # regressor effects\n",
    "dC = 10 + 3 * np.random.randn(NU, K)  # latent effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressors and latent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1273c2630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5UAAACMCAYAAADsmY0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124f23a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dX = 1 + np.random.randn(P, NS)\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "ddelta = stats.beta.rvs(1.2, 1, size=(K,))\n",
    "dpi = np.cumprod(ddelta)\n",
    "dZ = stats.bernoulli.rvs(dpi[:, np.newaxis], size=(K, NS))\n",
    "\n",
    "# plot states\n",
    "plt.matshow(dZ, aspect='auto', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate trial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dU, dS = np.meshgrid(range(NU), range(NS))\n",
    "dU = dU.ravel()\n",
    "dS = dS.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dlam_mean = dA[dU] + np.sum(dB[dU] * dX[:, dS].T, axis=1) + np.sum(dC[dU] * dZ[:, dS].T, axis=1)\n",
    "\n",
    "dlam = stats.norm.rvs(loc=dlam_mean, scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1273962b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dlam, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll want this function below\n",
    "def softplus(x):\n",
    "    return np.logaddexp(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcount = stats.poisson.rvs(softplus(dlam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE+dJREFUeJzt3W2MZFd95/Hvz8+ExGY2WncLxnggbIyxNiBrBWTZVUo4\nC4ZItl+sLEgW4SDxBjagICFmyAvPq00cKUJIu7xAsNYs4kEGNvIgIXkyGkorVotIZCwT23htIT/E\nZBohMJJZhGzz3xd17SnPdPd01731dO/3I42m6nbde8/p6v71qXPPOTdVhSRpGC5YdgEkSYtj6EvS\ngBj6kjQghr4kDYihL0kDYuhL0oCcN/STfD7JVpL7p7b9dZKHktyX5OtJLp/62pEkjzRff8e8Ci5J\n2r+9tPTvBN551rYTwHVV9SbgEeAIQJI3ALcC1wLvAj6TJN0VV5LUxnlDv6q+DfzsrG0nq+rXzdPv\nAAebxzcBX6mq56rqMSZ/EN7cXXElSW100af/AeCbzeNXAU9Ofe2pZpskaQW0Cv0kfwE8W1Vf7qg8\nkqQ5umjWHZPcBrwbePvU5qeAq6aeH2y2bbe/i/5I0gyqauZrpXtt6af5N3mS3Ah8HLipqn419brj\nwHuSXJLkNcDrgO/udNCq6u2/22+/fellsH7Wb4j163Pdqtq3lc/b0k/yJWAE/HaSJ4DbgU8ClwB/\n1wzO+U5VfaiqHkxyF/Ag8CzwoeqilJKkTpw39Kvqj7fZfOcur/9L4C/bFEqSNB/OyJ2T0Wi07CLM\nlfVbb32uX5/r1oUsq/cliT0/krRPSagFXMiVJPWAoS9JA2LoS9KAGPqSNCCGviQNiKEvSQNi6EvS\ngBj6kjQghr4kDYihL0kDYuhL0oAY+pI0IIa+lmJz8xBJXvy3uXlo2UWSBsFVNrUUk5vvTL//6eSu\nQFLfucqmJGnPDH1JGhBDX5IGxNCXpAEx9CVpQAx9SRoQQ1+SBsTQl6QBMfQlaUAMfUkaEENfkgbE\n0JekATlv6Cf5fJKtJPdPbTuQ5ESSh5Pck+SKqa8dSfJIkoeSvGNeBZck7d9eWvp3Au88a9th4GRV\nXQOcAo4AJHkDcCtwLfAu4DOZLKcoSVoB5w39qvo28LOzNt8MHGseHwNuaR7fBHylqp6rqseAR4A3\nd1NUSVJbs/bpX1lVWwBVdRq4stn+KuDJqdc91WyTJK2Ari7kevcLSVoDF82431aSjaraSrIJ/LjZ\n/hRw1dTrDjbbtnX06NEXH49GI0aj0YzFkaR+Go/HjMfjzo63p9slJjkEfKOq/nXz/A7gp1V1R5JP\nAAeq6nBzIfeLwFuYdOv8HfCvtrsvordLHDZvlyjNpu3tEs/b0k/yJWAE/HaSJ4Dbgb8CvprkA8Dj\nTEbsUFUPJrkLeBB4FviQyS5Jq8Mbo2spbOlLs/HG6JKkPTP0JWlADH1JGhBDX5IGxNCXpAEx9CVp\nQAx9SRoQQ1+SBsTQl6QBMfQlaUAMfUkaEENfkgbE0JekATH0JWlADH1JGhBDX5IGxNCXpAEx9CVp\nQAx9SRoQQ1+SBsTQl6QBMfQlaUAMfe1qc/MQSUjC5uahZRdHUkupquWcOKllnVt7lwR44X0KXb1n\nLz1ut8eW+iwJVZVZ97elr97x04m0M1v62tU6tvTnVWZpFdjSF2DrVtLe2NLvicW0yG3pS8tmS1+S\ntGetQj/Jnyf5xyT3J/likkuSHEhyIsnDSe5JckVXhZUktTNz6Cd5JfBnwPVV9XvARcB7gcPAyaq6\nBjgFHOmioJKk9tp271wIvDzJRcDLgKeAm4FjzdePAbe0PIckqSMzh35V/Qj4G+AJJmH/86o6CWxU\n1VbzmtPAlV0UVJLU3kWz7pjkFUxa9VcDPwe+muRPeOmQDLZ5/qKjR4+++Hg0GjEajWYtjiT10ng8\nZjwed3a8mYdsJvmPwDur6oPN8/cBbwXeDoyqaivJJvCtqrp2m/0dstkhh2zudGyHbKpfljlk8wng\nrUkuy+S37AbgQeA4cFvzmvcDd7c4hySpQzN371TVd5N8Dfge8Gzz/2eB3wLuSvIB4HHg1i4KKklq\nzxm5PWH3zk7HtntH/eKMXEnSnhn6kjQghr4kDYihL0kDYuhL0oAY+pI0IIa+JA2IoS9JA2LoS9KA\nGPqSNCCGviQNiKEvSQNi6EvSgBj6kjQghr4kDYihL0kDYuhL0oAY+pI0IIa+JA2IoS9JA2LoS9KA\nGPqSNCCGviQNiKEvSQNi6EvSgBj6kjQghr4kDYihL0kD0ir0k1yR5KtJHkryQJK3JDmQ5ESSh5Pc\nk+SKrgorSWqnbUv/08A3q+pa4I3AD4DDwMmqugY4BRxpeQ5JUkdSVbPtmFwOfK+qfues7T8A/qCq\ntpJsAuOqev02+9es59a5kgAvfD9DV9/bxRx3nsfu7rjSKkhCVWXW/du09F8D/CTJnUnuTfLZJL8B\nbFTVFkBVnQaubHEOSVKHLmq57/XAh6vqH5J8iknXztnNqh2bWUePHn3x8Wg0YjQatSiOtDibm4fY\n2nocgI2Nqzl9+rHlFki9NR6PGY/HnR2vTffOBvB/quq1zfN/xyT0fwcYTXXvfKvp8z97f7t3OmT3\nzk7Hnk/3jl1IWpalde80XThPJvndZtMNwAPAceC2Ztv7gbtnPYckqVszt/QBkrwR+BxwMfBD4E+B\nC4G7gKuAx4Fbq+rpbfa1pd8hW/o7HduWvvqlbUu/Vei3Yeh3y9Df6diGvvplmaN3JElrxtCXpAEx\n9CVpQAx99dylJCEJm5uHll0YaenaTM6S1sCveOGC69bWzNe+pN6wpS9JA2LoS9KAGPqSNCCGvjq3\nuXlo24un09slLYczcntilWbk7rTP2dsXNSN3Vb4vUheckauecGiltAgO2dSKcGiltAi29NWJnfvr\nL7Uffx+mv49+6tE82KffE8vu09+tH/38j8/9Wsslv3c856r36c9z9VH1g336kqQ9M/QlaUAMfa29\ns/vBuzyeferqG/v0e2LIffrb9YO36dPfS53t09ey2Ke/ZpbZinRkiCRb+gu2zBb5ua3Iy5iMj4eN\njas5ffqxmctrS9+WvhajbUvfyVmD5oQoaWjs3tE5hrAwmhdrNVR27yzYanXv7HdhtP507+z2/bJ7\nR6vMC7na1RBa7fPlQnDqF1v6C7bolv75ljO2pX/u+fZSf1v6WhZb+lqKridESVoMR+9oJltbj3Nu\n61rSqrOlr5XmKBupW61DP8kFSe5Ncrx5fiDJiSQPJ7knyRXti6mhOvOJoprHktrooqX/UeDBqeeH\ngZNVdQ1wCjjSwTm0L/2/cYmjkqTZtAr9JAeBdwOfm9p8M3CseXwMuKXNOTSLF2ba9nfUx/QnAEl7\n17al/yng47z0N2+jqrYAquo0cGXLc2gh9vLpoP+fIKS+m3n0TpI/Araq6r4ko11eumNT7OjRoy8+\nHo1GjEa7HUbzdWYdnp1H4uzlNX12qX/wtHDj8ZjxeNzZ8WaenJXkvwD/CXgOeBnwW8DfAv8GGFXV\nVpJN4FtVde02+zs5a46Ts2aZENXl5KquJmd1Memsy8lZi733brfHVj8sbXJWVX2yql5dVa8F3gOc\nqqr3Ad8Abmte9n7g7lnPIUnq1jzG6f8V8B+SPAzc0DyXJK0A195ZMLt37N7Zjd07Oh/X3pEk7Zmh\nL0kDYuhL0oC4yqZW0E7j4R0nL7VlS18raKdlJPq/vIQ0b4a+tAQuGa1lccjmgjlkc7llWZUhm3sb\nijrbsdVvDtnsud1ahC4v3JUzC8n5vVTf2dJfsP229LtukdrSbze5y5a+ls2WviRpzwx9aSC8eCxw\nnL40GGfuNgZbW167GCpb+tLSrfcdyfwEsV68kLtgXsj1Qu7u55/fhdxFDRce4u/1Inkht4ccijkv\n692ilrpg6K+gM32vtpi65TIOkqEvSQNi6EvSgBj6kjQghr4kDYihL7V2qePUtTackSu19sKoIGe6\navXZ0pekATH0pTlyiQKtGrt3pDlykTOtGlv6Uqe6vguXF4nVLVv6UqfOXNSdaBv8XiRWt2zprxXv\n5arV4KKA62vm0E9yMMmpJA8k+X6SjzTbDyQ5keThJPckuaK74g7d9IJhLhqm5XFRwPXVpqX/HPCx\nqroO+H3gw0leDxwGTlbVNcAp4Ej7YkqSujBz6FfV6aq6r3n8DPAQcBC4GTjWvOwYcEvbQkqSutFJ\nn36SQ8CbgO8AG1W1BZM/DMCVXZxD0hntx/87KmioWo/eSfKbwNeAj1bVM0nO7uSz00/qWPvx/44K\nGqpWoZ/kIiaB/4WqurvZvJVko6q2kmwCP95p/6NHj774eDQaMRqN2hSnM5ubh5pfqomNjas5ffqx\n5RVI0mCNx2PG43Fnx2t1Y/Qk/wP4SVV9bGrbHcBPq+qOJJ8ADlTV4W32Xdkbo7/0Rs+wiJtIn/2H\npk83I7cs+7kx+yz7X8ak5b57A2W3c273c9j2WJqPtjdGnzn0k7wN+F/A9zkzduuTwHeBu4CrgMeB\nW6vq6W32N/T3HQLrE26WZftjzSf09xa6e9lnp5/PWY6l+Wgb+jN371TV/wYu3OHLfzjrcaX+unSh\nk5nO/fQouQyDtEDTSzTMP/ynL/Yu6pxafS7DsE/dLpV7ZticJC2CLf196nap3MW2/CTJ0Jd6ZbHX\nDbR+7N6RemV6UT7pXIZ+o8ulYqePdeGFL3c5ZPWCyyn3Q6vJWa1OvGLj9Hcedzx5vp9xzOc71hDG\no1uW+ZRlXvM69vLzvddzrtLvdR+1HadvS78jtoIkrQNDvyPeVELSOnD0jrQ2HJmj9gz9PfGXTatg\n0fM6/LnvI0N/T5xEpSGa/rkHf/b7wdCXBs8W/ZB4IVcaPCd0DcmgQ99hltL8dLs4oboy6MlZs97I\nosubYqzSxB/LYlm62H+/N2TR/jg5S1Iv7bacSZtPDtPHHeKnEFv6tvRX4FiWpU9l6aqlv9elUfZr\nnrdDXQRb+vtkP760uvz9nL/Bhb7LJUiry9/P+Rtc6Euap51uAXrpjv3obVv3jhLan8H16S9qSdo+\n9dFaFssyj7K0XSZ61msHQ+/Td0aupCVwFvCy2L0jaQmcBbwsaxv6VcWjjz764r+NjauX0K+3U/+l\npPk6/7WDeeXAul9DWNs+/WPHjvHBD36ESy/9lzz//P/jl7/8Z3bq19vcPNSMCnjBuvarrnYfrWWx\nLKtVlsuYfKKAjY2rOX36sckrzunT3/51O1n2TOPBjtN/+umnSW7jmWce5Ze//OKur3UYmDREZ7qQ\nXtrom/V1/bC2oS9J3WvXPbQOXT9zC/0kNyb5QZL/m+QT8zqPJHWnXat/uldhVT81zCX0k1wA/Ffg\nncB1wHuTvH4e59reSyeCLMd4SedVN8bLLoBmNt5mm4MuXjCvlv6bgUeq6vGqehb4CnDznM61jenh\nYMvqxx8v6bzqxnjZBdDMxttsc4joC+YV+q8Cnpx6/k/NNklaE2c+HUwv7bzTa3b72vT+04936/ff\naWnpttZ2Ru7FF1/MBRcc5/LLf8jzz/+EX/xi2SWS1C9nbgz/61+fPSz03Nfs9rXp/acfb23tHOJn\nrg/sdv79m8s4/SRvBY5W1Y3N88NAVdUdU6/xc5YkzaDNOP15hf6FwMPADcA/A98F3ltVD3V+MknS\nns2le6eqnk/yn4ETTK4bfN7Al6TlW9oyDJKkxVvKjNw+TdxKcjDJqSQPJPl+ko802w8kOZHk4ST3\nJLli2WVtI8kFSe5Ncrx53pv6JbkiyVeTPNS8j2/pWf3+PMk/Jrk/yReTXLLO9Uvy+SRbSe6f2rZj\nfZIcSfJI8/6+Yzml3rsd6vfXTfnvS/L1JJdPfW1f9Vt46C9/4lbnngM+VlXXAb8PfLipz2HgZFVd\nA5wCjiyxjF34KPDg1PM+1e/TwDer6lrgjcAP6En9krwS+DPg+qr6PSZduu9lvet3J5P8mLZtfZK8\nAbgVuBZ4F/CZrP4Mre3qdwK4rqreBDxCi/oto6W/5Ilb3aqq01V1X/P4GeAh4CCTOh1rXnYMuGU5\nJWwvyUHg3cDnpjb3on5Ni+nfV9WdAFX1XFX9nJ7Ur3Eh8PIkFwEvA55ijetXVd8GfnbW5p3qcxPw\nleZ9fYxJYL55EeWc1Xb1q6qTVfXr5ul3mGQMzFC/ZYR+byduJTkEvInJm7JRVVsw+cMAXLm8krX2\nKeDjvHRAcl/q9xrgJ0nubLqvPpvkN+hJ/arqR8DfAE8wCfufV9VJelK/KVfuUJ+z8+Yp1j9vPgB8\ns3m87/q5ymZHkvwm8DXgo02L/+wr5Gt5xTzJHwFbzaeZ3T42rmX9mHR3XA/8t6q6HvgFk66Cvrx/\nr2DSCr4aeCWTFv+f0JP67aJv9QEgyV8Az1bVl2c9xjJC/yng1VPPDzbb1lbzsflrwBeq6u5m81aS\njebrm8CPl1W+lt4G3JTkh8CXgbcn+QJwuif1+yfgyar6h+b515n8EejL+/eHwA+r6qdV9Tzwt8C/\npT/1e8FO9XkKuGrqdWubN0luY9LN+sdTm/ddv2WE/t8Dr0tydZJLgPcAx5dQji79d+DBqvr01Lbj\nwG3N4/cDd5+90zqoqk9W1aur6rVM3qtTVfU+4Bv0o35bwJNJfrfZdAPwAD15/5h067w1yWXNBb4b\nmFyQX/f6hZd+8typPseB9zQjll4DvI7JZNFV95L6JbmRSRfrTVX1q6nX7b9+VbXwf8CNTGbsPgIc\nXkYZOqzL24DngfuA7wH3NvX7F8DJpp4ngFcsu6wd1PUPgOPN497Uj8mInb9v3sP/CVzRs/rdzmSA\nwf1MLnJevM71A74E/IjJ4jZPAH8KHNipPkxGujzafA/esezyz1i/R4DHm3y5F/jMrPVzcpYkDYgX\nciVpQAx9SRoQQ1+SBsTQl6QBMfQlaUAMfUkaEENfkgbE0JekAfn/d8RgXeNd4iUAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127a2f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dcount, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = dcount\n",
    "Xdat = dX[:, dS].T\n",
    "Xdat.shape\n",
    "unit = dU\n",
    "stim = dS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define some needed constants\n",
    "N = Xdat.shape[0]  # number of trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(Xdat.astype('float32'))\n",
    "U = tf.constant(unit)\n",
    "S = tf.constant(stim)\n",
    "counts = tf.constant(count)\n",
    "allinds = tf.constant(np.arange(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a node that produces `NB` indices from the range $[0, N - 1]$. These are the subset of data points we want to use."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "batch_inds = tf.train.range_input_producer(N).dequeue_many(NB, name='batch_inds')\n",
    "batch_counts = tf.train.batch(tf.train.slice_input_producer([counts]), NB, name='batch_counts')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "batch_inds = tf.constant(np.arange(NB))\n",
    "batch_counts = tf.train.batch(tf.train.slice_input_producer([counts]), NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_inds, batch_counts = tf.train.batch(tf.train.slice_input_producer([allinds, counts]), NB, \n",
    "                                          name='batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative (p) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"pmodel\"):\n",
    "    A = ed.models.Normal(mu=tf.zeros(NU), sigma=tf.ones(NU), name='A')\n",
    "    B = ed.models.Normal(mu=tf.zeros((NU, P)), sigma=tf.ones((NU, P)), name='B')\n",
    "    C = ed.models.Normal(mu=tf.zeros((NU, K)), sigma=tf.ones((NU, K)), name='C')  \n",
    "    \n",
    "    delta = ed.models.Beta(a=3 * tf.ones(K), b=tf.ones(K), name='delta')\n",
    "    tf.scalar_summary('mean_delta', tf.reduce_mean(delta))\n",
    "    log_delta = tf.log(delta)\n",
    "    tf.scalar_summary('min_log_delta', tf.reduce_min(log_delta))\n",
    "    tf.scalar_summary('mean_log_delta', tf.reduce_mean(log_delta))\n",
    "\n",
    "    pi = tf.exp(tf.cumsum(log_delta), name='pi')\n",
    "    tf.scalar_summary('min_pi', tf.reduce_min(pi))\n",
    "\n",
    "    Z = ed.models.Bernoulli(p=tf.tile(tf.expand_dims(pi, 0), [NS, 1]), name='Z')\n",
    "    tf.scalar_summary('mean_Z', tf.reduce_mean(tf.to_float(Z)))\n",
    "\n",
    "    sig = ed.models.Normal(mu=[-0.1], sigma=[0.1], name='sig')\n",
    "\n",
    "    lam_vars = (tf.gather(A, U) + tf.reduce_sum(tf.gather(B, U) * X, 1) + \n",
    "           tf.reduce_sum(tf.gather(C, U) * tf.gather(tf.to_float(Z), S), 1))\n",
    "    lam = ed.models.Normal(mu=tf.gather(lam_vars, batch_inds), \n",
    "                           sigma=tf.exp(sig), name='lam')\n",
    "    tf.scalar_summary('mean_lam', tf.reduce_mean(lam))\n",
    "\n",
    "\n",
    "    cnt = ed.models.Poisson(lam=tf.nn.softplus(lam), value=tf.ones(NB), name='cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition (q) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"qmodel\"):\n",
    "    q_A = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((NU,))), \n",
    "                                            sigma=tf.Variable(tf.random_uniform((NU,))),\n",
    "                                            name='A')\n",
    "    q_B = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((NU, P))), \n",
    "                                            sigma=tf.Variable(tf.random_uniform((NU, P))),\n",
    "                                            name='B')\n",
    "    q_C = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(tf.random_normal((NU, K))), \n",
    "                                            sigma=tf.Variable(tf.random_uniform((NU, K))),\n",
    "                                            name='C')\n",
    "    q_Z = ed.models.BernoulliWithSigmoidP(p=tf.Variable(tf.random_normal((NS, K))), name='Z')\n",
    "    tf.scalar_summary('mean_q_Z', tf.reduce_mean(tf.to_float(Z)))\n",
    "\n",
    "    q_delta = ed.models.BetaWithSoftplusAB(a=tf.Variable(1 + tf.random_uniform((K,))),\n",
    "                                           b=tf.Variable(1 + tf.random_uniform((K,))),\n",
    "                                           name='delta')\n",
    "    tf.scalar_summary('mean_q_delta', tf.reduce_mean(q_delta))\n",
    "\n",
    "    lam_mu = tf.Variable(tf.random_normal((N,)))\n",
    "    lam_sig = tf.Variable(tf.random_uniform((N,)))\n",
    "    q_lam = ed.models.NormalWithSoftplusSigma(mu=tf.gather(lam_mu, batch_inds),\n",
    "                                              sigma=tf.gather(lam_sig, batch_inds),\n",
    "                                              name='lam')\n",
    "    tf.scalar_summary('mean_q_lam', tf.reduce_mean(q_lam))\n",
    "\n",
    "    q_sig = ed.models.NormalWithSoftplusSigma(mu=tf.Variable(-0.1 * tf.random_uniform((1,))),\n",
    "                                              sigma=tf.Variable(tf.random_uniform((1,))),\n",
    "                                              name='sig')\n",
    "    tf.scalar_summary('mean_q_sig', tf.reduce_mean(q_sig))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {cnt: batch_counts}\n",
    "inference = ed.KLqp({A: q_A, B: q_B, C: q_C, Z: q_Z, sig: q_sig, delta: q_delta, lam: q_lam}, \n",
    "                    data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes before inference:\n",
    "\n",
    "- The `logdir` keyword specifies the place to put the log file (assuming you've instrumented the code to save events, etc.). If a subdirectory is given, pointing Tensorboard at the parent directory allows you to compare across subdirectories (runs).\n",
    "    - I'm using the `jmp/instrumented` branch of the `jmxpearson/edward` fork\n",
    "- I had to lower the learning rate in Adam to avoid NaNs early on in learning. Gradient clipping might solve the same problem.\n",
    "- I'm currently using \"all\" the data, but this should probably be switched to minibatches.\n",
    "- I've used `n_samples` = 1, 5, 10, and 25, which all seem pretty similar after 10k iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     1 [  0%]: Loss = 5870.929\n",
      "Iteration   100 [  0%]: Loss = 1217434.250\n",
      "Iteration   200 [  0%]: Loss = 8064.021\n",
      "Iteration   300 [  1%]: Loss = 8637.578\n",
      "Iteration   400 [  1%]: Loss = 40519.207\n",
      "Iteration   500 [  1%]: Loss = 4612.165\n",
      "Iteration   600 [  2%]: Loss = 6471.989\n",
      "Iteration   700 [  2%]: Loss = 104030.555\n",
      "Iteration   800 [  2%]: Loss = 93775.609\n",
      "Iteration   900 [  3%]: Loss = 27486.777\n",
      "Iteration  1000 [  3%]: Loss = 11892.262\n",
      "Iteration  1100 [  3%]: Loss = 14055.564\n",
      "Iteration  1200 [  4%]: Loss = 4086.376\n",
      "Iteration  1300 [  4%]: Loss = 57433.691\n",
      "Iteration  1400 [  4%]: Loss = 9025.950\n",
      "Iteration  1500 [  5%]: Loss = 6685.343\n",
      "Iteration  1600 [  5%]: Loss = 4513.907\n",
      "Iteration  1700 [  5%]: Loss = 7447.272\n",
      "Iteration  1800 [  6%]: Loss = 37310.449\n",
      "Iteration  1900 [  6%]: Loss = 18839.092\n",
      "Iteration  2000 [  6%]: Loss = 36025.047\n",
      "Iteration  2100 [  7%]: Loss = 6813.926\n",
      "Iteration  2200 [  7%]: Loss = 8373.320\n",
      "Iteration  2300 [  7%]: Loss = 51297.406\n",
      "Iteration  2400 [  8%]: Loss = 58126.352\n",
      "Iteration  2500 [  8%]: Loss = 91793.781\n",
      "Iteration  2600 [  8%]: Loss = 31512.609\n",
      "Iteration  2700 [  9%]: Loss = 218664.266\n",
      "Iteration  2800 [  9%]: Loss = 51463.492\n",
      "Iteration  2900 [  9%]: Loss = 76922.938\n",
      "Iteration  3000 [ 10%]: Loss = 11519.252\n",
      "Iteration  3100 [ 10%]: Loss = 17980.342\n",
      "Iteration  3200 [ 10%]: Loss = 27216.234\n",
      "Iteration  3300 [ 11%]: Loss = 6987.461\n",
      "Iteration  3400 [ 11%]: Loss = 4689.945\n",
      "Iteration  3500 [ 11%]: Loss = 18336.387\n",
      "Iteration  3600 [ 12%]: Loss = 5628.723\n",
      "Iteration  3700 [ 12%]: Loss = 204936.391\n",
      "Iteration  3800 [ 12%]: Loss = 5770.644\n",
      "Iteration  3900 [ 13%]: Loss = 430188.812\n",
      "Iteration  4000 [ 13%]: Loss = 96802.547\n",
      "Iteration  4100 [ 13%]: Loss = 8357.678\n",
      "Iteration  4200 [ 14%]: Loss = 34173.027\n",
      "Iteration  4300 [ 14%]: Loss = 5907.116\n",
      "Iteration  4400 [ 14%]: Loss = 42789.812\n",
      "Iteration  4500 [ 15%]: Loss = 6015.128\n",
      "Iteration  4600 [ 15%]: Loss = 3746.182\n",
      "Iteration  4700 [ 15%]: Loss = 7100.989\n",
      "Iteration  4800 [ 16%]: Loss = 139693.062\n",
      "Iteration  4900 [ 16%]: Loss = 14288.611\n",
      "Iteration  5000 [ 16%]: Loss = 3396.408\n",
      "Iteration  5100 [ 17%]: Loss = 22157.684\n",
      "Iteration  5200 [ 17%]: Loss = 334235.406\n",
      "Iteration  5300 [ 17%]: Loss = 98896.188\n",
      "Iteration  5400 [ 18%]: Loss = 7078.685\n",
      "Iteration  5500 [ 18%]: Loss = 26319.459\n",
      "Iteration  5600 [ 18%]: Loss = 23270.668\n",
      "Iteration  5700 [ 19%]: Loss = 7839.647\n",
      "Iteration  5800 [ 19%]: Loss = 13328.036\n",
      "Iteration  5900 [ 19%]: Loss = 6713.854\n",
      "Iteration  6000 [ 20%]: Loss = 4237.116\n",
      "Iteration  6100 [ 20%]: Loss = 5703.110\n",
      "Iteration  6200 [ 20%]: Loss = 16952.094\n",
      "Iteration  6300 [ 21%]: Loss = 49213.293\n",
      "Iteration  6400 [ 21%]: Loss = 10950.639\n",
      "Iteration  6500 [ 21%]: Loss = 16613.547\n",
      "Iteration  6600 [ 22%]: Loss = 4277.264\n",
      "Iteration  6700 [ 22%]: Loss = 12850.127\n",
      "Iteration  6800 [ 22%]: Loss = 53239.086\n",
      "Iteration  6900 [ 23%]: Loss = 40469.590\n",
      "Iteration  7000 [ 23%]: Loss = 14296.682\n",
      "Iteration  7100 [ 23%]: Loss = 4052.254\n",
      "Iteration  7200 [ 24%]: Loss = 5003.280\n",
      "Iteration  7300 [ 24%]: Loss = 8552.779\n",
      "Iteration  7400 [ 24%]: Loss = 9016.990\n",
      "Iteration  7500 [ 25%]: Loss = 26522.555\n",
      "Iteration  7600 [ 25%]: Loss = 21613.531\n",
      "Iteration  7700 [ 25%]: Loss = 20737.781\n",
      "Iteration  7800 [ 26%]: Loss = 9051.715\n",
      "Iteration  7900 [ 26%]: Loss = 4795.335\n",
      "Iteration  8000 [ 26%]: Loss = 113804.688\n",
      "Iteration  8100 [ 27%]: Loss = 31954.242\n",
      "Iteration  8200 [ 27%]: Loss = 16010.953\n",
      "Iteration  8300 [ 27%]: Loss = 6586.522\n",
      "Iteration  8400 [ 28%]: Loss = 5551.459\n",
      "Iteration  8500 [ 28%]: Loss = 56259.852\n",
      "Iteration  8600 [ 28%]: Loss = 5425.462\n",
      "Iteration  8700 [ 28%]: Loss = 4559.812\n",
      "Iteration  8800 [ 29%]: Loss = 3861.357\n",
      "Iteration  8900 [ 29%]: Loss = 6193.594\n",
      "Iteration  9000 [ 30%]: Loss = 16116.873\n",
      "Iteration  9100 [ 30%]: Loss = 10080.812\n",
      "Iteration  9200 [ 30%]: Loss = 20405.510\n",
      "Iteration  9300 [ 31%]: Loss = 32151.754\n",
      "Iteration  9400 [ 31%]: Loss = 4449.709\n",
      "Iteration  9500 [ 31%]: Loss = 5163.575\n",
      "Iteration  9600 [ 32%]: Loss = 4964.378\n",
      "Iteration  9700 [ 32%]: Loss = 5165.404\n",
      "Iteration  9800 [ 32%]: Loss = 4010.313\n",
      "Iteration  9900 [ 33%]: Loss = 8524.313\n",
      "Iteration 10000 [ 33%]: Loss = 5810.618\n",
      "Iteration 10100 [ 33%]: Loss = 6374.984\n",
      "Iteration 10200 [ 34%]: Loss = 12526.295\n",
      "Iteration 10300 [ 34%]: Loss = 11680.142\n",
      "Iteration 10400 [ 34%]: Loss = 5208.314\n",
      "Iteration 10500 [ 35%]: Loss = 31707.121\n",
      "Iteration 10600 [ 35%]: Loss = 4298.807\n",
      "Iteration 10700 [ 35%]: Loss = 4475.203\n",
      "Iteration 10800 [ 36%]: Loss = 5280.181\n",
      "Iteration 10900 [ 36%]: Loss = 4834.250\n",
      "Iteration 11000 [ 36%]: Loss = 4942.724\n",
      "Iteration 11100 [ 37%]: Loss = 22661.086\n",
      "Iteration 11200 [ 37%]: Loss = 4583.623\n",
      "Iteration 11300 [ 37%]: Loss = 4639.047\n",
      "Iteration 11400 [ 38%]: Loss = 6170.536\n",
      "Iteration 11500 [ 38%]: Loss = 5651.882\n",
      "Iteration 11600 [ 38%]: Loss = 4543.978\n",
      "Iteration 11700 [ 39%]: Loss = 5262.478\n",
      "Iteration 11800 [ 39%]: Loss = 5044.370\n",
      "Iteration 11900 [ 39%]: Loss = 3964.880\n",
      "Iteration 12000 [ 40%]: Loss = 5521.880\n",
      "Iteration 12100 [ 40%]: Loss = 4375.167\n",
      "Iteration 12200 [ 40%]: Loss = 6689.712\n",
      "Iteration 12300 [ 41%]: Loss = 5554.941\n",
      "Iteration 12400 [ 41%]: Loss = 5217.971\n",
      "Iteration 12500 [ 41%]: Loss = 3758.891\n",
      "Iteration 12600 [ 42%]: Loss = 4132.231\n",
      "Iteration 12700 [ 42%]: Loss = 4901.869\n",
      "Iteration 12800 [ 42%]: Loss = 3395.207\n",
      "Iteration 12900 [ 43%]: Loss = 5874.669\n",
      "Iteration 13000 [ 43%]: Loss = 4258.777\n",
      "Iteration 13100 [ 43%]: Loss = 3719.444\n",
      "Iteration 13200 [ 44%]: Loss = 5664.875\n",
      "Iteration 13300 [ 44%]: Loss = 3912.104\n",
      "Iteration 13400 [ 44%]: Loss = 16776.871\n",
      "Iteration 13500 [ 45%]: Loss = 4233.300\n",
      "Iteration 13600 [ 45%]: Loss = 8819.926\n",
      "Iteration 13700 [ 45%]: Loss = 4455.101\n",
      "Iteration 13800 [ 46%]: Loss = 6120.866\n",
      "Iteration 13900 [ 46%]: Loss = 4228.527\n",
      "Iteration 14000 [ 46%]: Loss = 3388.822\n",
      "Iteration 14100 [ 47%]: Loss = 3624.517\n",
      "Iteration 14200 [ 47%]: Loss = 4368.079\n",
      "Iteration 14300 [ 47%]: Loss = 4472.561\n",
      "Iteration 14400 [ 48%]: Loss = 5003.563\n",
      "Iteration 14500 [ 48%]: Loss = 6133.622\n",
      "Iteration 14600 [ 48%]: Loss = 2379.951\n",
      "Iteration 14700 [ 49%]: Loss = 4854.881\n",
      "Iteration 14800 [ 49%]: Loss = 3933.009\n",
      "Iteration 14900 [ 49%]: Loss = 5140.140\n",
      "Iteration 15000 [ 50%]: Loss = 4652.211\n",
      "Iteration 15100 [ 50%]: Loss = 3539.669\n",
      "Iteration 15200 [ 50%]: Loss = 5170.133\n",
      "Iteration 15300 [ 51%]: Loss = 4803.420\n",
      "Iteration 15400 [ 51%]: Loss = 5628.594\n",
      "Iteration 15500 [ 51%]: Loss = 6081.570\n",
      "Iteration 15600 [ 52%]: Loss = 5377.720\n",
      "Iteration 15700 [ 52%]: Loss = 11506.218\n",
      "Iteration 15800 [ 52%]: Loss = 3778.843\n",
      "Iteration 15900 [ 53%]: Loss = 7094.085\n",
      "Iteration 16000 [ 53%]: Loss = 4521.869\n",
      "Iteration 16100 [ 53%]: Loss = 5150.760\n",
      "Iteration 16200 [ 54%]: Loss = 5885.414\n",
      "Iteration 16300 [ 54%]: Loss = 5284.543\n",
      "Iteration 16400 [ 54%]: Loss = 3414.764\n",
      "Iteration 16500 [ 55%]: Loss = 6704.643\n",
      "Iteration 16600 [ 55%]: Loss = 7018.026\n",
      "Iteration 16700 [ 55%]: Loss = 3540.682\n",
      "Iteration 16800 [ 56%]: Loss = 5720.678\n",
      "Iteration 16900 [ 56%]: Loss = 5410.363\n",
      "Iteration 17000 [ 56%]: Loss = 4601.845\n",
      "Iteration 17100 [ 56%]: Loss = 5160.525\n",
      "Iteration 17200 [ 57%]: Loss = 4226.356\n",
      "Iteration 17300 [ 57%]: Loss = 4731.764\n",
      "Iteration 17400 [ 57%]: Loss = 5009.245\n",
      "Iteration 17500 [ 58%]: Loss = 5375.889\n",
      "Iteration 17600 [ 58%]: Loss = 6439.188\n",
      "Iteration 17700 [ 59%]: Loss = 5331.637\n",
      "Iteration 17800 [ 59%]: Loss = 4921.607\n",
      "Iteration 17900 [ 59%]: Loss = 5017.662\n",
      "Iteration 18000 [ 60%]: Loss = 5339.750\n",
      "Iteration 18100 [ 60%]: Loss = 5261.667\n",
      "Iteration 18200 [ 60%]: Loss = 5887.896\n",
      "Iteration 18300 [ 61%]: Loss = 5567.464\n",
      "Iteration 18400 [ 61%]: Loss = 5262.121\n",
      "Iteration 18500 [ 61%]: Loss = 3449.824\n",
      "Iteration 18600 [ 62%]: Loss = 5424.354\n",
      "Iteration 18700 [ 62%]: Loss = 3698.716\n",
      "Iteration 18800 [ 62%]: Loss = 6998.207\n",
      "Iteration 18900 [ 63%]: Loss = 3425.697\n",
      "Iteration 19000 [ 63%]: Loss = 4106.535\n",
      "Iteration 19100 [ 63%]: Loss = 4497.208\n",
      "Iteration 19200 [ 64%]: Loss = 5371.879\n",
      "Iteration 19300 [ 64%]: Loss = 8045.176\n",
      "Iteration 19400 [ 64%]: Loss = 7099.200\n",
      "Iteration 19500 [ 65%]: Loss = 4983.734\n",
      "Iteration 19600 [ 65%]: Loss = 5507.873\n",
      "Iteration 19700 [ 65%]: Loss = 4757.523\n",
      "Iteration 19800 [ 66%]: Loss = 3787.808\n",
      "Iteration 19900 [ 66%]: Loss = 4529.389\n",
      "Iteration 20000 [ 66%]: Loss = 4918.780\n",
      "Iteration 20100 [ 67%]: Loss = 5831.740\n",
      "Iteration 20200 [ 67%]: Loss = 4696.858\n",
      "Iteration 20300 [ 67%]: Loss = 5631.049\n",
      "Iteration 20400 [ 68%]: Loss = 4607.770\n",
      "Iteration 20500 [ 68%]: Loss = 4186.878\n",
      "Iteration 20600 [ 68%]: Loss = 3379.581\n",
      "Iteration 20700 [ 69%]: Loss = 5504.797\n",
      "Iteration 20800 [ 69%]: Loss = 3610.092\n",
      "Iteration 20900 [ 69%]: Loss = 4197.599\n",
      "Iteration 21000 [ 70%]: Loss = 5134.015\n",
      "Iteration 21100 [ 70%]: Loss = 4494.201\n",
      "Iteration 21200 [ 70%]: Loss = 5704.107\n",
      "Iteration 21300 [ 71%]: Loss = 4492.739\n",
      "Iteration 21400 [ 71%]: Loss = 5896.033\n",
      "Iteration 21500 [ 71%]: Loss = 5616.943\n",
      "Iteration 21600 [ 72%]: Loss = 5575.887\n",
      "Iteration 21700 [ 72%]: Loss = 5381.715\n",
      "Iteration 21800 [ 72%]: Loss = 4483.690\n",
      "Iteration 21900 [ 73%]: Loss = 5445.334\n",
      "Iteration 22000 [ 73%]: Loss = 4747.893\n",
      "Iteration 22100 [ 73%]: Loss = 3401.411\n",
      "Iteration 22200 [ 74%]: Loss = 3485.545\n",
      "Iteration 22300 [ 74%]: Loss = 3926.608\n",
      "Iteration 22400 [ 74%]: Loss = 3017.353\n",
      "Iteration 22500 [ 75%]: Loss = 4642.176\n",
      "Iteration 22600 [ 75%]: Loss = 5463.936\n",
      "Iteration 22700 [ 75%]: Loss = 4739.060\n",
      "Iteration 22800 [ 76%]: Loss = 4760.939\n",
      "Iteration 22900 [ 76%]: Loss = 4141.542\n",
      "Iteration 23000 [ 76%]: Loss = 6034.438\n",
      "Iteration 23100 [ 77%]: Loss = 4097.717\n",
      "Iteration 23200 [ 77%]: Loss = 5433.211\n",
      "Iteration 23300 [ 77%]: Loss = 3501.989\n",
      "Iteration 23400 [ 78%]: Loss = 4697.389\n",
      "Iteration 23500 [ 78%]: Loss = 4314.073\n",
      "Iteration 23600 [ 78%]: Loss = 6925.271\n",
      "Iteration 23700 [ 79%]: Loss = 4552.256\n",
      "Iteration 23800 [ 79%]: Loss = 4550.460\n",
      "Iteration 23900 [ 79%]: Loss = 4718.711\n",
      "Iteration 24000 [ 80%]: Loss = 3860.730\n",
      "Iteration 24100 [ 80%]: Loss = 5276.868\n",
      "Iteration 24200 [ 80%]: Loss = 4815.042\n",
      "Iteration 24300 [ 81%]: Loss = 4701.250\n",
      "Iteration 24400 [ 81%]: Loss = 3808.162\n",
      "Iteration 24500 [ 81%]: Loss = 4330.242\n",
      "Iteration 24600 [ 82%]: Loss = 7293.758\n",
      "Iteration 24700 [ 82%]: Loss = 5698.634\n",
      "Iteration 24800 [ 82%]: Loss = 4349.233\n",
      "Iteration 24900 [ 83%]: Loss = 5241.915\n",
      "Iteration 25000 [ 83%]: Loss = 6808.478\n",
      "Iteration 25100 [ 83%]: Loss = 5669.995\n",
      "Iteration 25200 [ 84%]: Loss = 5340.781\n",
      "Iteration 25300 [ 84%]: Loss = 4118.974\n",
      "Iteration 25400 [ 84%]: Loss = 4273.308\n",
      "Iteration 25500 [ 85%]: Loss = 3599.058\n",
      "Iteration 25600 [ 85%]: Loss = 4943.019\n",
      "Iteration 25700 [ 85%]: Loss = 4517.625\n",
      "Iteration 25800 [ 86%]: Loss = 3911.098\n",
      "Iteration 25900 [ 86%]: Loss = 6004.527\n",
      "Iteration 26000 [ 86%]: Loss = 4261.390\n",
      "Iteration 26100 [ 87%]: Loss = 5791.394\n",
      "Iteration 26200 [ 87%]: Loss = 5091.029\n",
      "Iteration 26300 [ 87%]: Loss = 4667.835\n",
      "Iteration 26400 [ 88%]: Loss = 5052.301\n",
      "Iteration 26500 [ 88%]: Loss = 4479.292\n",
      "Iteration 26600 [ 88%]: Loss = 5932.633\n",
      "Iteration 26700 [ 89%]: Loss = 4059.923\n",
      "Iteration 26800 [ 89%]: Loss = 6603.240\n",
      "Iteration 26900 [ 89%]: Loss = 4554.353\n",
      "Iteration 27000 [ 90%]: Loss = 3889.390\n",
      "Iteration 27100 [ 90%]: Loss = 5226.448\n",
      "Iteration 27200 [ 90%]: Loss = 4085.381\n",
      "Iteration 27300 [ 91%]: Loss = 5390.525\n",
      "Iteration 27400 [ 91%]: Loss = 4684.116\n",
      "Iteration 27500 [ 91%]: Loss = 4285.451\n",
      "Iteration 27600 [ 92%]: Loss = 4890.805\n",
      "Iteration 27700 [ 92%]: Loss = 5300.754\n",
      "Iteration 27800 [ 92%]: Loss = 4981.402\n",
      "Iteration 27900 [ 93%]: Loss = 4264.295\n",
      "Iteration 28000 [ 93%]: Loss = 5387.562\n",
      "Iteration 28100 [ 93%]: Loss = 5121.015\n",
      "Iteration 28200 [ 94%]: Loss = 3689.082\n",
      "Iteration 28300 [ 94%]: Loss = 5667.680\n",
      "Iteration 28400 [ 94%]: Loss = 3564.728\n",
      "Iteration 28500 [ 95%]: Loss = 3789.670\n",
      "Iteration 28600 [ 95%]: Loss = 4640.727\n",
      "Iteration 28700 [ 95%]: Loss = 4857.186\n",
      "Iteration 28800 [ 96%]: Loss = 3848.400\n",
      "Iteration 28900 [ 96%]: Loss = 4721.522\n",
      "Iteration 29000 [ 96%]: Loss = 5144.563\n",
      "Iteration 29100 [ 97%]: Loss = 4841.023\n",
      "Iteration 29200 [ 97%]: Loss = 3511.138\n",
      "Iteration 29300 [ 97%]: Loss = 5309.258\n",
      "Iteration 29400 [ 98%]: Loss = 4813.967\n",
      "Iteration 29500 [ 98%]: Loss = 5498.054\n",
      "Iteration 29600 [ 98%]: Loss = 4421.895\n",
      "Iteration 29700 [ 99%]: Loss = 3742.969\n",
      "Iteration 29800 [ 99%]: Loss = 4303.165\n",
      "Iteration 29900 [ 99%]: Loss = 4812.447\n",
      "Iteration 30000 [100%]: Loss = 3761.944\n"
     ]
    }
   ],
   "source": [
    "inference.run(n_iter=30000, n_print=100, n_samples=1,\n",
    "              logdir='data/run1',\n",
    "              optimizer=tf.train.AdamOptimizer(1e-3),\n",
    "              scale={lam: N/NB, cnt: N/NB})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a735358>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5UAAACMCAYAAADsmY0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127c41cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5UAAACMCAYAAADsmY0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAAMJmmEgAAgMn+Dx4nWHUbiAgoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1291af780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Zmat = q_Z.value().eval()\n",
    "\n",
    "plt.matshow(dZ, aspect='auto', cmap='gray')\n",
    "plt.matshow(Zmat.T, aspect='auto', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
